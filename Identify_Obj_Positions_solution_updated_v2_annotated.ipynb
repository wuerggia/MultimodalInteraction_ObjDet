{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9343f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Importiert YOLO, lädt ein vortrainiertes Modell, sucht die Klassen-ID des Zielobjekts,\n",
    "# und führt Inferenz aus. Der Code ist hier auskommentiert, damit die Zelle nicht ausgeführt wird.\n",
    "# from ultralytics import YOLO\n",
    "#\n",
    "#\n",
    "#\n",
    "# # Load the YOLOv8 pre-trained model\n",
    "# model = YOLO('yolov8n.pt')  # nano model for quick inference\n",
    "#\n",
    "#\n",
    "# # Get the class ID for the target object\n",
    "# target_object_name = \"cup\"  # Replace with your target object name\n",
    "# class_names = model.names\n",
    "# target_class_id = next((class_id for class_id, name in class_names.items() if name == target_object_name), None)\n",
    "#\n",
    "#\n",
    "#\n",
    "# if target_class_id is not None:\n",
    "#     # Perform inference\n",
    "#     results = model('images/table_scene.jpeg', save = True)  # Replace with your image path\n",
    "#\n",
    "#     # Filter bounding boxes for the target object\n",
    "#     detections = results[0].boxes\n",
    "#     specific_boxes = [\n",
    "#         box.xyxy[0].tolist()\n",
    "#         for box in detections\n",
    "#         if int(box.cls[0]) == target_class_id\n",
    "#     ]\n",
    "#\n",
    "#     print(f\"Bounding boxes for '{target_object_name}': {specific_boxes}\")\n",
    "# else:\n",
    "#     print(f\"Object name '{target_object_name}' not found in the model's class names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cad2e",
   "metadata": {},
   "source": [
    "### Utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a62e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Hilfsfunktionen zum Zeichnen von Bounding-Boxes auf Bildern und zum Parsen von textuellen Box-Antworten.\n",
    "# Die Implementierung ist auskommentiert, damit die Zelle nicht ausgeführt wird.\n",
    "#\n",
    "# import json\n",
    "# import re\n",
    "# from PIL import Image, ImageDraw\n",
    "# from PIL import ImageColor\n",
    "#\n",
    "# additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "#\n",
    "# #this function is needed to plot bounding boxes on images \n",
    "# def plot_bounding_boxes(im, positions):\n",
    "#     \"\"\"\n",
    "#     Plots bounding boxes on an image with markers for each noun phrase, using PIL, normalized coordinates, and different colors.\n",
    "#\n",
    "#     Args:\n",
    "#         img_path: The path to the image file.\n",
    "#         noun_phrases_and_positions: A list of tuples containing the noun phrases\n",
    "#          and their positions in normalized [y1 x1 y2 x2] format.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # Load the image\n",
    "#     img = im\n",
    "#     width, height = img.size\n",
    "#     print(img.size)\n",
    "#     # Create a drawing object\n",
    "#     draw = ImageDraw.Draw(img)\n",
    "#\n",
    "#     # Define a list of colors\n",
    "#     colors = [\n",
    "#     'red',\n",
    "#     'green',\n",
    "#     'blue',\n",
    "#     'yellow',\n",
    "#     'orange',\n",
    "#     ] + additional_colors\n",
    "#\n",
    "#     # Iterate over the noun phrases and their positions\n",
    "#     for i, ((y1, x1, y2, x2)) in enumerate(positions):\n",
    "#         # Select a color from the list\n",
    "#         color = colors[i % len(colors)]\n",
    "#\n",
    "#         # Convert normalized coordinates to absolute coordinates\n",
    "#         abs_x1 = int(x1/1000 * width)\n",
    "#         abs_y1 = int(y1/1000 * height)\n",
    "#         abs_x2 = int(x2/1000 * width)\n",
    "#         abs_y2 = int(y2/1000 * height)\n",
    "#\n",
    "#         # Draw the bounding box\n",
    "#         draw.rectangle(\n",
    "#             ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "#         )\n",
    "#\n",
    "#         # Draw the text\n",
    "#         #draw.text((abs_x1 + 8, abs_y1 + 6), noun_phrase, fill=color)\n",
    "#\n",
    "#     # Display the image\n",
    "#     img.show()\n",
    "#\n",
    "# # if the boxes coordinates are output not as json but as text, should be parsed first\n",
    "# def parse_list_boxes(text):\n",
    "#   result = []\n",
    "#   for line in text.strip().splitlines():\n",
    "#     # Extract the numbers from the line, remove brackets and split by comma\n",
    "#     try:\n",
    "#       numbers = line.split('[')[1].split(']')[0].split(',')\n",
    "#     except:\n",
    "#       numbers =  line.split('- ')[1].split(',')\n",
    "#\n",
    "#     # Convert the numbers to integers and append to the result\n",
    "#     result.append([int(num.strip()) for num in numbers])\n",
    "#\n",
    "#   return result\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c39d8e",
   "metadata": {},
   "source": [
    "# VLM (1): OPEN-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Setup für OpenAI-Client, Bild-Encoder-Funktion und Bildpfad. Code auskommentiert.\n",
    "# import openai\n",
    "# from dotenv import load_dotenv  \n",
    "# import base64\n",
    "#\n",
    "# # Function to encode the image\n",
    "# def encode_image(image_path):\n",
    "#   with open(image_path, \"rb\") as image_file:\n",
    "#     return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "#\n",
    "# load_dotenv()\n",
    "# openAIclient = openai.OpenAI()\n",
    "#\n",
    "# img = \"images/table_scene.jpeg\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6cd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Beispielaufruf an GPT4 mit Bild, um Koordinaten einer Tasse im JSON-Format zurückzubekommen.\n",
    "# Der eigentliche Aufruf ist auskommentiert, damit beim Laden keine API-Aufrufe erfolgen.\n",
    "# import json\n",
    "#\n",
    "# completion = openAIclient.chat.completions.create(\n",
    "#     model=\"gpt-4.1-mini\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": \"Detect if there is a cup in the image and reutrn its coordinates as a list in the format [ymin,xmin, ymax, xmax], normalize the coordinate to 0-1000. Just output the list in json.\"},\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": {\n",
    "#                         \"url\": f\"data:image/jpeg;base64,{encode_image(img)}\",\n",
    "#                     }\n",
    "#                 },\n",
    "#             ],\n",
    "#         }\n",
    "#     ],\n",
    "#     response_format={\"type\": \"json_object\"},\n",
    "# )\n",
    "#\n",
    "# # Wrap the text to a specified width\n",
    "# response = str(completion.choices[0].message.content)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da8851",
   "metadata": {},
   "source": [
    "Load answer in a python dict and/or parse the json before if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Lade die JSON-Antwort in ein Python-Dictionary (auskommentiert, damit kein Fehler auftritt falls `response` fehlt).\n",
    "# detection = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Zeige das geladene Detection-Objekt an (auskommentiert).\n",
    "# detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a6909",
   "metadata": {},
   "source": [
    "now parse and plot bounding boxes. Consider the format the utils function want the bounding boxes to be plotted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2831d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Bereitet die Box-Koordinaten vor und ruft die Hilfsfunktion zum Plotten auf.\n",
    "# Die Zeilen sind auskommentiert, so dass nichts ausgeführt wird beim Öffnen.\n",
    "# boxes= parse_list_boxes(str(detection['coordinates'])) #depending whether you managed to output a json or not. If your output is still in \"str\" form you might need to parse it with this util function\n",
    "# boxes= [detection['coordinates']]\n",
    "# print(boxes)\n",
    "# plot_bounding_boxes(Image.open(img), positions=list(boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9df9a",
   "metadata": {},
   "source": [
    "# VLM (2): GEMINI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a573fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Setup für Google Gemini-Client (API-Key aus der Umgebung). Code ist auskommentiert.\n",
    "# %matplotlib inline\n",
    "# from dotenv import load_dotenv  \n",
    "# from google import genai\n",
    "# from PIL import Image\n",
    "#\n",
    "# load_dotenv()\n",
    "# client = genai.Client()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31691597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Anfrage an Gemini senden, um die Position der Tasse zu bestimmen und die Antwort als JSON auszugeben.\n",
    "# Der eigentliche Aufruf ist auskommentiert, damit keine API-Anfrage ausgeführt wird.\n",
    "# im = Image.open(img)\n",
    "#\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     contents=[\n",
    "#         im,\n",
    "#         (\n",
    "#             \"Detect if there is a cup in the image and reutrn its coordinates as a list in the format [ymin,xmin, ymax, xmax], normalize the coordinate to 0-1000. answer should be json format only\"\n",
    "#         ),\n",
    "#         \n",
    "#     ],\n",
    "#     config={\"response_mime_type\": \"application/json\"},\n",
    "# )\n",
    "#\n",
    "# print(response.text)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e1492",
   "metadata": {},
   "source": [
    "Ah! Output is a list! because I asked for it in the prompt - either you leave it and take account in parsing, or you remove the word \"list\" in prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca32d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Versucht, die JSON-Antwort von Gemini zu laden (auskommentiert).\n",
    "# json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung: Parsen der Antwort und Plotten der Bounding-Box (auskommentiert).\n",
    "# boxes= parse_list_boxes(response.text) # same comment as above\n",
    "# box_coord = [json.loads(response.text)[0]['box_2d']] #due to the fact it is a list, otherwise this line might change\n",
    "# plot_bounding_boxes(im,positions=list(box_coord))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
